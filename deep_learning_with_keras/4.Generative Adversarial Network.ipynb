{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Generative Adversarial Network / 적대적 생성 네트워크\n",
    "\n",
    "- 인공 데이터 재생산 방법을 학습\n",
    "    - WaveNet : 사람 목소리와 악기 소리 재생산\n",
    "    - Zhang, Han, et al. \"Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks.\" Proceedings of the IEEE International Conference on Computer Vision. 2017. 텍스트를 기반으로 이미지 생성\n",
    "    \n",
    "    \n",
    "- 두 개의 신경망을 동시에 학습한다.\n",
    "    - 생성기 : 위조\n",
    "    - 판별기 : 얼마나 진짜 같은지 판단\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras-adversarial : 파이썬 패키지\n",
    "\n",
    "git clone --depth=50 --branch=master https://github.com/bstriner/keras-adversarial.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Dropout, LeakyReLU, Input, Activation\n",
    "from keras.models import Model\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_adversarial.legacy import Dense, BatchNormalization, Convolution2D\n",
    "from keras_adversarial.image_grid_callback import ImageGridCallback\n",
    "from keras_adversarial import AdversarialModel, simple_gan, gan_targets\n",
    "from keras_adversarial import AdversarialOptimizerSimultaneous, normal_latent_sampling\n",
    "from image_utils import dim_ordering_fix, dim_ordering_input, dim_ordering_reshape, dim_ordering_unfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n targets k players\n",
    "\n",
    "def gan_targets(n):\n",
    "    generator_fake = np.ones((n, 1))\n",
    "    generator_real = np.zeros((n, 1))\n",
    "    discriminator_fake = np.zeros((n, 1))\n",
    "    discriminator_real = np.ones((n, 1))\n",
    "    \n",
    "    return [generator_fake, generator_real, discriminator_fake, discriminator_real]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_generator():\n",
    "    nch = 256\n",
    "    g_input = Input(shape=[100])\n",
    "    H = Dense(nch * 14 * 14)(g_input)\n",
    "    H = BatchNormalization(mode=2)(H)\n",
    "    H = Activation('relu')(H)\n",
    "    H = dim_ordering_reshape(nch, 14)(H)\n",
    "    H = UpSampling2D(size=(2,2))(H)\n",
    "    H = Convolution2D(int(nch /2), 3, 3, border_mode=\"same\")(H)\n",
    "    H = BatchNormalization(mode=2, axis=1)(H)\n",
    "    H = Activation('relu')(H)\n",
    "    H = Convolution2D(int(nch /4), 3, 3, border_mode=\"same\")(H)\n",
    "    H = BatchNormalization(mode=2, axis=1)(H)\n",
    "    H = Activation('relu')(H)\n",
    "    H = Convolution2D(1, 1, 1, border_mode=\"same\")(H)\n",
    "    g_V = Activation('sigmoid')(H)\n",
    "    return Model(g_input, g_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_discriminator(input_shape=(1,28,28), dropout_rate=0.5):\n",
    "    d_input = dim_ordering_input(input_shape, name=\"input_x\")\n",
    "    nch = 512\n",
    "    H = Convolution2D(int(nch /2), 5, 5, subsample=(2,2), border_mode=\"same\", activation='relu')(d_input)\n",
    "    H = LeakyReLU(0.2)(H)\n",
    "    H = Dropout(dropout_rate)(H)\n",
    "    H = Convolution2D(nch, 5, 5, subsample=(2,2), border_mode=\"same\", activation='relu')(H)\n",
    "    H = LeakyReLU(0.2)(H)\n",
    "    H = Dropout(dropout_rate)(H)\n",
    "    H = Flatten()(H)\n",
    "    H = Dense(int(nch/2))(H)\n",
    "    H = LeakyReLU(0.2)(H)    \n",
    "    H = Dropout(dropout_rate)(H)\n",
    "    d_V = Dense(1, activation='sigmoid')(H)\n",
    "    return Model(d_input, d_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_process(x):\n",
    "    x = x.astype(np.float32)/255.0\n",
    "    return x\n",
    "\n",
    "def mnist_data():\n",
    "    (xtrain, ytrain), (xtest,ytest) = mnist.load_data()\n",
    "    return mnist_process(xtrain), mnist_process(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "\n",
    "input_shape= (1, 28, 28)\n",
    "generator = model_generator()\n",
    "discriminator = model_discriminator(input_shape=input_shape)\n",
    "\n",
    "gan = simple_gan(generator, discriminator, normal_latent_sampling((latent_dim,)))\n",
    "\n",
    "generator.summary()\n",
    "discriminator.summary()\n",
    "\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN\n",
    "\n",
    "model = AdversarialModel(base_model=gan,\\\n",
    "                        player_params =[generator.trainable_weights, \\\n",
    "                                       discriminator.trainable_weights],\\\n",
    "                        player_names=['generator', 'discriminator'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.adversarial_compile(adversarial_optimizer=AdversarialOptimizerSimultaneous(),\\\n",
    "                         player_optimizers=[Adam(1e-4, decay=1e-4), Adam(1e-3, decay=1e-4)],\\\n",
    "                         loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_sampler():\n",
    "    zsamples = np.random.normal(size=(10*10, latent_dim))\n",
    "    gen = dim_ordering_unfix(generator.predict(zsamples))\n",
    "    return gen.reshape((10, 10, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_cb = ImageGridCallback(\"gan_output/gan_conv/epoch-{:03d}.png\", generator_sampler)\n",
    "\n",
    "xtrain, xtest = mnist_data()\n",
    "xtrain = dim_ordering_fix(xtrain.reshape((-1, 1, 28, 28)))\n",
    "xtest = dim_ordering_fix(xtest.reshape((-1, 1, 28, 28)))\n",
    "\n",
    "y = gan_targets(xtrain.shape[0])\n",
    "ytest = gan_targets(xtest.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=xtrain, y=y,\\\n",
    "                   validation_data=(xtest, ytest), \\\n",
    "                    callbacks=[generator_cb], nb_epoch=100, batch_size=32)\n",
    "df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"gan_output/gan_conv/history.csv\")\n",
    "generator.save(\"gan_output/gan_conv/generator.h5\")\n",
    "discriminator.save(\"gan_output/gan_conv/discriminator.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
