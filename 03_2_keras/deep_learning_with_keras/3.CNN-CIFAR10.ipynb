{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCNN : CNN + Pooling\n",
    "\n",
    "- 지역 수용 영역 : 지역적인 구조를 인코딩 - 인접한 입력 뉴런의 부분 행렬들을 다음 계층에 있는 한 개의 은닉 뉴런으로 연결\n",
    "- 풀링 : 맵 출력을 요약, 하나의 특징 맵으로부터 나온 출력에서 공간 인접성을 활용해 부분 행렬 값들을 물리적인 지역에 관련된 의미를 종합적으로 설명하는 출력 값으로 결합\n",
    "\n",
    "    - max pooling : 관찰한 최대 활성화를 출력\n",
    "    model.add(MaxPooling2D(pool_size= (2,2))\n",
    "    - avg pooling :\n",
    "    \n",
    "- DCNN의 낮은 계층에서는 색상이나 가장자리 같은 낮은 차원의 특징을 식별.\n",
    "- 중간계층은 이미지에서 중요한 특징을 추출할 수 있는 능력을 가지고 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dense, Dropout\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes):\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, padding='same', input_shape=input_shape))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "        model.add(Dropout(0.25))\n",
    "                \n",
    "        model.add(Flatten())\n",
    "        \n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCH = 20\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "\n",
    "OPTIMIZER = RMSprop()\n",
    "VALIDATION_SPLIT = 0.2\n",
    "IMG_CHANNEL, IMG_ROWS, IMG_COLS = 3, 32, 32\n",
    "NB_CLASSES = 10\n",
    "INPUT_SHAPE = (IMG_ROWS, IMG_COLS, IMG_CHANNEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "y_test = np_utils.to_categorical(y_test, NB_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Simple.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, \\\n",
    "                   batch_size=BATCH_SIZE, epochs=NB_EPOCH,\\\n",
    "                   verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "score = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class More_Layer:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes):\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, padding='same', input_shape=input_shape))\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "        model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Conv2D(64, kernel_size=3, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=3, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        \n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = More_Layer.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, \\\n",
    "                   batch_size=BATCH_SIZE, epochs=NB_EPOCH,\\\n",
    "                   verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "score = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More data\n",
    "- 데이터셋의 회전, 크기 조정, 수평 수직 뒤집기, 확대 축소, 채널 이동등의 변형을 통해 데이터를 증가시킬 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "NUM_TO_AUGMENT = 5\n",
    "\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=40,\\\n",
    "    width_shift_range=0.2,\\\n",
    "    height_shift_range=0.2, \\\n",
    "    zoom_range=0.2,\\\n",
    "    horizontal_flip=True,\\\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtas, ytas = [], []\n",
    "for i in range(X_train.shape[0]):\n",
    "    num_aug = 0\n",
    "    x = X_train[i]\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    \n",
    "    for x_aug in data_gen.flow(x, batch_size=1, save_to_dir='./cifar_preview',\\\n",
    "                              save_prefix='cifar', save_format='jpeg'):\n",
    "        if num_aug >= NUM_TO_AUGMENT:\n",
    "            break\n",
    "        xtas.append(x_aug[0])\n",
    "        num_aug += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(data_gen.flow(X_train, y_train, batch_size=BATCH_SIZE), \\\n",
    "                              steps_per_epoch=X_train.shape[0], epochs=NB_EPOCH, verbose=VERBOSE)\n",
    "score = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "open('cifar10_arch.json', 'w').write(model_json)\n",
    "model.save_weights('cifar10_we.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
